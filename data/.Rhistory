lapply(DF, function(x) grep('Archived at',x))
lapply(DF, function(x) grep('Archived at',x), simplify=TRUE)
lapply(DF, function(x) grep('Archived at',x))
items<-lapply(DF, function(x) grep('Archived at',x))
datelines<-lapply(DF, function(x) grep('Archived at',x))
items<-DF[grep('Archived at',DF[items])]
DF[datelines]
DF[,datelines]
DF[[datelines]]
DF[[,datelines]]
DF[datelines,]
df<-unlist(DF)
grep('Archived at',df)
datelines<-df[grep('Archived at',df)]
datelines<-df[grep('Archived at',df)] ### Select only lines in html containing "Archived at"
findlines<-df[grep('Archived at',df)] ### Select only lines in html containing "Archived at"
foundlines<-df[grep('Archived at',df)] ### Select only lines in html containing "Archived at"
mypattern = 'Archived at: ([^<]*)</span>' # Define a pattern to identify dates
datelines = grep(mypattern,foundlines,value=TRUE)
datelines
getexpr = function(s,g)substring(s,g,g+attr(g,'match.length')-1)
gg = gregexpr(mypattern,datelines)
matches = mapply(getexpr,datelines,gg)
result = gsub(mypattern,'\\1',matches)
names(result) = NULL
result
data <- as.data.frame(matrix(result,ncol=1,byrow=TRUE))
names(data) = c('date')
head(data)
require(lubridate)
?guess_formats
guess_formats(data$date, print_matches = TRUE)
guess_formats(data$date, order="1979-05-27 05:00:59" print_matches = TRUE)
data$year<-year(data$date)
date$year
data$year
summary(data$year)
summary(as.factor(data$year))
counts(as.factor(data$year))
count(as.factor(data$year))
table(as.factor(data$year))
timeseries<-table(as.factor(data$year))
timeseries<-as.data.frame(as.factor(data$year))
timeseries
timeseries<-as.data.frame(table(as.factor(data$year)))
View(timeseries)
View(timeseries)
View(timeseries)
require(ggplot2)
View(timeseries)
summary(timeseries$Freq)
summary(timeseries$Var1)
timeseries<-as.data.frame(table(data$year))
View(timeseries)
summary(timeseries$Var1)
data$year<-year(data$date)
timeseries<-as.data.frame(table(data$year))
View(timeseries)
summary(timeseries$Var1)
timeseries<-as.data.frame(table(as.numeric(data$year)))
summary(timeseries$Var1)
data$year<-year(data$date)
timeseries<-as.data.frame(table(as.numeric(data$year)))
summary(timeseries$Var1)
qplot(as.numeric(timeseries$Var1), timeseries$Freq)
qplot(timeseries$Var1, timeseries$Freq)
?qplot
qplot(timeseries$Var1, timeseries$Freq, geom="line") + theme_bw()
qplot(timeseries$Var1, timeseries$Freq, geom="line")
?qplot
qplot(timeseries$Var1, timeseries$Freq) + geom(line)
qplot(timeseries$Var1, timeseries$Freq) + geom_line() + theme_bw()
View(timeseries)
qplot(as.numeric(timeseries$Var1), timeseries$Freq) + geom_line() + theme_bw()
qplot(as.integer(timeseries$Var1), timeseries$Freq) + geom_line() + theme_bw()
?qplot
?geom_line
?qplot
qplot(Var1, Freq, data=timeseries) + geom_line() + theme_bw()
qplot(Var1, Freq, data=timeseries) + geom_line() + theme_bw()
?geom_line
qplot(Var1, Freq, data=timeseries) + geom_line(aes(Var1, Freq, data=timeseries)) + theme_bw()
?geom_line
data$year<-as.Date(data$year)
qplot(Var1, Freq, data=timeseries, geom="line") + theme_bw()
?lubridate
data$year<-year(data$date)
timeseries<-as.data.frame(table(data$year))
timeseries$year<-year(timeseries$year)
View(timeseries)
timeseries$year<-year(as.numeric(timeseries$year))
timeseries<-as.data.frame(table(data$date))
View(timeseries)
?as.Date
data$year<-year(data$date)
data$year<-as.Date(data$year)
timeseries<-as.data.frame(table(data$year))
data$year<-year(data$date)
timeseries<-as.data.frame(table(data$year))
View(timeseries)
timeseries$Year<-as.Date(timeseries$Var1, "%Y")
qplot(Year, Freq, data=timeseries, geom="line") + theme_bw()
?qplot
qplot(Year, Freq, data=timeseries, geom="line", main="Frequency of \"wage\" in Archive of Prime Minister's Website) + theme_bw()
qplot(Year, Freq, data=timeseries, geom="line", main="Frequency of /"wage/" in Archive of Prime Minister's Website) + theme_bw()
qplot(Year, Freq, data=timeseries, geom="line", main="Frequency of "wage" in Archive of Prime Minister's Website) + theme_bw()
qplot(Year, Freq, data=timeseries, geom="line", main="Frequency of "wage" in Archive of Prime Minister's Website") + theme_bw()
qplot(Year, Freq, data=timeseries, geom="line", main="Frequency of "\wage\" in Archive of Prime Minister's Website") + theme_bw()
qplot(Year, Freq, data=timeseries, geom="line", main="Frequency of \"wage\" in Archive of Prime Minister's Website") + theme_bw()
qplot(Year, Freq, data=timeseries, geom="line", main="Frequency of \"wage\" in National Archive of Prime Minister's Website") + theme_bw()
searchterm<-"wage"
totalresults<-"1000"
############################################################
### Creates the sequence of numbers to paginate with
pages<-seq(0, as.numeric(totalresults), 10)
### Make a character vector of URLs of all the search results
urls<-sprintf("http://webarchive.nationalarchives.gov.uk/search/?lang=en&noneW=&format=all&department_id_51=on&department_id_56=on&site=number10.gov.uk&department_id_54=on&search_type=website&start=%s&x=17&y=13&query=%s&exactW=&where=text", pages, searchterm)
### Read the html of each results page into a list
for(i in 1:length(urls)){
DF<-lapply(urls, function(x) readLines(x))
}
DF[99]
require(XML)
require(RCurl)
totalresults<-"200"
searchterm<-"wage"
require(XML)
require(RCurl)
pages<-seq(0, as.numeric(totalresults), 1)
urls<-sprintf("http://tnaftindex.internetmemory.org/nutch-1.0-tna-distrib-ssd/opensearch?query=%s&page=%s", searchterm, pages)
for(i in 1:length(urls)){
DF<-lapply(urls, function(x) xmlParse(x))
}
DF[1]
DF[199]
mat<-matrix(ncols=20, nrows=200)
mat<-matrix[ncols=20, nrows=200]
mat<-matrix[nrows=200, ncols=20]
?matrix
mat<-matrix[nrow=200, ncols=5]
mat<-matrix(nrow=200, ncols=5)
mat<-matrix(nrow=200, ncol=5)
?matrix
mat<-as.data.frame(matrix(nrow=200, ncol=5))
head(mat)
names(mat)<-c("Year", "Wage", "Profit", "Inequality", "Inflation", "Unemployment")
names(mat)<-c("Year", "Wage", "Profit", "Inflation", "Unemployment")
df<-as.data.frame(matrix(nrow=200, ncol=5))
names(df)<-c("Year", "Wage", "Profit", "Inflation", "Unemployment")
?runif
df$year<-runif(200, min=0, max=100)
head(df)
df<-as.data.frame(matrix(nrow=11, ncol=5))
df<-as.data.frame(matrix(nrow=12, ncol=5))
names(df)<-c("Year", "Wage", "Profit", "Inflation", "Unemployment")
df$year<-seq(11, min=2000, max=2012)
df<-as.data.frame(matrix(nrow=13, ncol=5))
names(df)<-c("Year", "Wage", "Profit", "Inflation", "Unemployment")
df$year<-seq(11, min=2000, max=2012)
?seq
df$year<-seq(11, from=2000, to=2011)
df<-as.data.frame(matrix(nrow=13, ncol=5))
names(df)<-c("Year", "Wage", "Profit", "Inflation", "Unemployment")
df$year<-seq(11, from=2000, to=2011)
df$year<-seq(from=2000, to=2011, by=1)
seq(from=2000, to=2011, by=1)
df<-as.data.frame(matrix(nrow=12, ncol=5))
names(df)<-c("Year", "Wage", "Profit", "Inflation", "Unemployment")
df$year<-seq(from=2000, to=2011, by=1)
head(df)
df$Year<-seq(from=2000, to=2011, by=1)
head(df)
df$Wage<-runif(12, min=0, max=100)
head(df)
df<-as.data.frame(matrix(nrow=12, ncol=5))
names(df)<-c("Year", "Wage", "Profit", "Inflation", "Unemployment")
df$Year<-seq(from=2000, to=2011, by=1)
df$Wage<-runif(12, min=0, max=100)
df$Profit<-runif(12, min=0, max=100)
df$Inflation<-runif(12, min=0, max=100)
df$Unemployment<-runif(12, min=0, max=100)
head(df)
searchterm<-"inequality"
searchterm<-"inequality"
totalresults<-"100"
pages<-seq(0, as.numeric(totalresults), 1)
urls<-sprintf("http://tnaftindex.internetmemory.org/nutch-1.0-tna-distrib-ssd/opensearch?query=%s&page=%s", searchterm, pages)
for(i in 1:length(urls)){
DF<-lapply(urls, function(x) xmlParse(x))
}
DF[101]
DF[80]
DF[30]
DF[[30]]
data<-unlist(DF)
titles <- xpathSApply(data,'//item/title',xmlValue)
for(i in 1:length(urls)){
DF<-lapply(urls, function(x) getURL(x))
}
titles <- xpathSApply(DF,'//item/title',xmlValue)
data<-unlist(DF)
data[1]
data[2]
data[9]
data[5]
#############################################################
#### Enter your search term and the total number of results
#### displayed by a search in the web browser.
searchterm<-"wage"
totalresults<-"1000"
############################################################
### Creates the sequence of numbers to paginate with
pages<-seq(0, as.numeric(totalresults), 10)
### Make a character vector of URLs of all the search results
urls<-sprintf("http://webarchive.nationalarchives.gov.uk/search/?lang=en&noneW=&format=all&department_id_51=on&department_id_56=on&site=number10.gov.uk&department_id_54=on&search_type=website&start=%s&x=17&y=13&query=%s&exactW=&where=text", pages, searchterm)
### Read the html of each results page into a list
for(i in 1:length(urls)){
DF<-lapply(urls, function(x) readLines(x))
}
df<-unlist(DF) ### Convert list of html docs to one character vector
foundlines<-df[grep('Archived at',df)] ### Select only lines in html containing "Archived at"
mypattern = 'Archived at: ([^<]*)</span>' # Define a pattern to identify dates
datelines = grep(mypattern,foundlines,value=TRUE)
getexpr = function(s,g)substring(s,g,g+attr(g,'match.length')-1)
gg = gregexpr(mypattern,datelines)
matches = mapply(getexpr,datelines,gg)
result = gsub(mypattern,'\\1',matches)
names(result) = NULL
result
data <- as.data.frame(matrix(result,ncol=1,byrow=TRUE))
names(data) = c('date')
head(data)
require(lubridate)
data$year<-year(data$date)
timeseries<-as.data.frame(table(data$year))
timeseries$Year<-as.Date(timeseries$Var1, "%Y")
require(ggplot2)
qplot(Year, Freq, data=timeseries, geom="line", main="Frequency of \"wage\" in National Archive of Prime Minister's Website") + theme_bw()
searchterm<-"wage"
totalresults<-"10000"
############################################################
### Creates the sequence of numbers to paginate with
pages<-seq(0, as.numeric(totalresults), 10)
### Make a character vector of URLs of all the search results
urls<-sprintf("http://webarchive.nationalarchives.gov.uk/search/?lang=en&noneW=&format=all&department_id_51=on&department_id_56=on&site=number10.gov.uk&department_id_54=on&search_type=website&start=%s&x=17&y=13&query=%s&exactW=&where=text", pages, searchterm)
### Read the html of each results page into a list
for(i in 1:length(urls)){
DF<-lapply(urls, function(x) readLines(x))
}
searchterm<-"wage"
totalresults<-"5000"
############################################################
### Creates the sequence of numbers to paginate with
pages<-seq(0, as.numeric(totalresults), 10)
### Make a character vector of URLs of all the search results
urls<-sprintf("http://webarchive.nationalarchives.gov.uk/search/?lang=en&noneW=&format=all&department_id_51=on&department_id_56=on&site=number10.gov.uk&department_id_54=on&search_type=website&start=%s&x=17&y=13&query=%s&exactW=&where=text", pages, searchterm)
### Read the html of each results page into a list
for(i in 1:length(urls)){
DF<-lapply(urls, function(x) readLines(x))
}
df<-unlist(DF) ### Convert list of html docs to one character vector
foundlines<-df[grep('Archived at',df)] ### Select only lines in html containing "Archived at"
mypattern = 'Archived at: ([^<]*)</span>' # Define a pattern to identify dates
datelines = grep(mypattern,foundlines,value=TRUE)
getexpr = function(s,g)substring(s,g,g+attr(g,'match.length')-1)
gg = gregexpr(mypattern,datelines)
matches = mapply(getexpr,datelines,gg)
result = gsub(mypattern,'\\1',matches)
names(result) = NULL
result
data <- as.data.frame(matrix(result,ncol=1,byrow=TRUE))
names(data) = c('date')
head(data)
require(lubridate)
data$year<-year(data$date)
timeseries<-as.data.frame(table(data$year))
timeseries$Year<-as.Date(timeseries$Var1, "%Y")
require(ggplot2)
qplot(Year, Freq, data=timeseries, geom="line", main="Frequency of \"wage\" in National Archive of Prime Minister's Website") + theme_bw()
?save
save(DF, "/Users/justin/Dropbox/Side Projects/uk_govt_web_archives/data/web_search_scrapes/wage_5000")
save(DF, "wage_5000")
save(DF, file="wage_5000")
save(DF, file="/Users/justin/Dropbox/Side Projects/uk_govt_web_archives/data/web_search_scrapes/wage_5000")
save(DF, file="/Users/justin/Dropbox/Side Projects/uk_govt_web_archives/data/web_search_scrapes/wage_5000.Rdata")
load("/Users/justin/Dropbox/Side Projects/uk_govt_web_archives/data/web_search_scrapes/wage_5000.Rdata")
rm(DF)
load("/Users/justin/Dropbox/Side Projects/uk_govt_web_archives/data/web_search_scrapes/wage_5000.Rdata")
searchterm<-"inequality"
require(XML)
require(RCurl)
pages<-seq(0, as.numeric(totalresults), 1)
urls<-sprintf("http://tnaftindex.internetmemory.org/nutch-1.0-tna-distrib-ssd/opensearch?query=%s?page=%s", searchterm, pages)
for(i in 1:length(urls)){
DF<-lapply(urls, function(x) getURL(x))
}
data<-unlist(DF)
data[1]
DF[1]
totalresults<-"500" # the real total is 335,5211 but baby steps
require(XML)
require(RCurl)
### Creates the sequence of numbers to paginate with
pages<-seq(0, as.numeric(totalresults), 1)
### Make a character vector of URLs of all the search results
urls<-sprintf("http://tnaftindex.internetmemory.org/nutch-1.0-tna-distrib-ssd/opensearch?query=%s?page=%s", searchterm, pages)
### Read the html of each results page into a list
for(i in 1:length(urls)){
DF<-lapply(urls, function(x) getURL(x))
}
searchterm<-"inequality"
totalpages<-"20"
pages<-seq(0, as.numeric(totalpages), 1)
pages
urls<-sprintf("http://tnaftindex.internetmemory.org/nutch-1.0-tna-distrib-ssd/opensearch?query=%s?page=%s", searchterm, pages)
urls
for(i in 1:length(urls)){
DF<-lapply(urls, function(x) getURL(x))
}
totalpages<-"10"
pages<-seq(0, as.numeric(totalpages), 1)
urls<-sprintf("http://tnaftindex.internetmemory.org/nutch-1.0-tna-distrib-ssd/opensearch?query=%s?page=%s", searchterm, pages)
for(i in 1:length(urls)){
DF<-lapply(urls, function(x) readLines(x))
}
warnings()
data<-unlist(DF)
doc  <- xmlParse(data)
doc  <- xmlParse(DF)
titles <- xpathSApply(data,'//item/title',xmlValue)
data<-lapply(DF, function(x) xmlParse(x))
titles <- lapply(data, function(x) xpathSApply(x,'//item/title',xmlValue))
titles[1]
titles[[1]]
descriptions <- lapply(data, function(x) xpathSApply(x,'//item/description',xmlValue))
contents <- lapply(data, function(x) xpathSApply(x,'//item/nutch:content',xmlValue))
descriptions[1]
descriptions[2]
dates <- lapply(data, function(x) xpathSApply(x,'//item/nutch:dates',xmlValue))
descriptions[1][1]
descriptions[1][[1]]
descriptions[[1][[1]]
descriptions[[1]][[1]]
dates[[1]]
dates[1]
dates <- lapply(data, function(x) xpathSApply(x,'//item/nutch:date',xmlValue))
dates[1]
datesdf<-unlist(dates)
head(datesdf)
table(dates)
datesdf<-as.data.frame(unlist(dates))
head(datesdf)
table(datesdf)
timeseries<-as.data.frame(table(datesdf))
head(timeseries)
?as.Date
require(lubridate)
timeseries$Year<-year(timeseries$datesdf)
?year
?grep
?substr
substr(timeseries$datesdf, start=1, stop=4)
timeseries$Year<-as.Date(substr(timeseries$datesdf, start=1, stop=4), "%Y")
View(timeseries)
substr(timeseries$datesdf, start=1, stop=4)
timeseries$Year<-substr(timeseries$datesdf, start=1, stop=4)
View(timeseries)
View(timeseries)
datesdf<-as.data.frame(unlist(dates))
View(datesdf)
?as.data.frame
datesdf<-as.data.frame(unlist(dates), optional=TRUE)
View(datesdf)
datesdf<-as.data.frame(unlist(dates), col.names="dates",optional=TRUE)
View(datesdf)
datesdf<-as.data.frame(unlist(dates), col.names="dates")
View(datesdf)
datesdf<-as.data.frame(unlist(dates))
timeseries<-as.data.frame(table(datesdf))
View(timeseries)
View(timeseries)
names(datesdf)<-c("timestamp")
View(datesdf)
datesdf$year<-substr(datesdf$timestamp, start=1, stop=4)
View(datesdf)
timeseries<-as.data.frame(table(datesdf$year))
timeseries
timeseries$Year<-as.Date(timeseries$Var1, "%Y")
timeseries
?as.Date
timeseries$Year<-as.Date(timeseries$Var1, format="%Y")
timeseries
timeseries$Year<-as.Date(timeseries$Var1)
require(lubridate)
timeseries$Year<-year(timeseries$Var1)
timeseries$Year<-year(as.numeric(timeseries$Var1))
timeseries$Year<-year(as.numeric(timeseries$Var1), origin="%Y")
timeseries$Year<-year(as.numeric(timeseries$Var1))
timeseries$Year<-as.Date(as.numeric(timeseries$Var1), "%Y")
View(timeseries)
?year
?guess_date
timeseries$Year<-as.Date(as.numeric(timeseries$Var1), format="%Y")
timeseries$Year<-as.Date(as.numeric(timeseries$Var1), origin="%Y")
summary(timeseries$Var1)
timeseries$Year<-as.Date(as.integer(timeseries$Var1), origin="%Y")
timeseries$Var1<-as.numeric(timeseries$Var1)
summary(timeseries$Var1)
timeseries$Var1<-as.integer(timeseries$Var1)
datesdf<-as.data.frame(unlist(dates))
names(datesdf)<-c("timestamp")
datesdf$year<-substr(datesdf$timestamp, start=1, stop=4)
timeseries<-as.data.frame(table(datesdf$year))
timeseries$Var1<-as.integer(timeseries$Var1)
summary(timeseries$Var1)
datesdf<-as.data.frame(unlist(dates))
names(datesdf)<-c("timestamp")
datesdf$year<-substr(datesdf$timestamp, start=1, stop=4)
timeseries<-as.data.frame(table(datesdf$year))
timeseries$Var1<-as.Date(timeseries$Var1)
timeseries$Var1<-as.Date(as.character(timeseries$Var1), format="%Y")
timeseries
?as.date
?as.Date
datesdf<-as.data.frame(unlist(dates))
names(datesdf)<-c("timestamp")
datesdf$year<-substr(datesdf$timestamp, start=1, stop=4)
timeseries<-as.data.frame(table(datesdf$year))
timeseries$Var1<-as.Date(as.character(timeseries$Var1), format="%Y")
timeseries$Year<-as.Date(timeseries$Var1, format="%Y", origin="%Y")
timeseries
datesdf<-as.data.frame(unlist(dates))
names(datesdf)<-c("timestamp")
datesdf$year<-substr(datesdf$timestamp, start=1, stop=4)
timeseries<-as.data.frame(table(datesdf$year))
timeseries$Var1<-as.Date(timeseries$year, format="%Y")
datesdf<-as.data.frame(unlist(dates))
names(datesdf)<-c("timestamp")
datesdf$year<-substr(datesdf$timestamp, start=1, stop=4)
timeseries<-as.data.frame(table(datesdf$year))
timeseries$Var1<-as.Date(timeseries$year, "%Y")
timeseries$Var1<-as.Date(as.character(timeseries$year), "%Y")
datesdf<-as.data.frame(unlist(dates))
names(datesdf)<-c("timestamp")
datesdf$year<-substr(datesdf$timestamp, start=1, stop=4)
timeseries<-as.data.frame(table(datesdf$year))
timeseries
timeseries$Year<-as.Date(as.character(timeseries$Var1), "%Y")
timeseries
timeseries$Year<-year(timeseries$Year)
timeseries
datesdf<-as.data.frame(unlist(dates))
names(datesdf)<-c("timestamp")
datesdf$year<-substr(datesdf$timestamp, start=1, stop=4)
timeseries<-as.data.frame(table(datesdf$year))
#timeseries$Year<-as.Date(as.character(timeseries$Var1), "%Y")
timeseries$Year<-year(timeseries$Var1)
datesdf<-as.data.frame(unlist(dates))
names(datesdf)<-c("timestamp")
datesdf$year<-substr(datesdf$timestamp, start=1, stop=4)
timeseries<-as.data.frame(table(datesdf$year))
timeseries$Year<-as.Date(as.character(timeseries$Var1), "%Y")
timeseries$Year<-year(timeseries$Year)
timeseries$Year
timeseries
require(ggplot2)
qplot(Year, Freq, data=timeseries, geom="line", main="Frequency of \"inequality\" in Across All UK Govt Websites") + theme_bw()
searchterm<-"inequality"
totalpages<-"50"
############################################################
setwd("~/Dropbox/Side Projects/uk_govt_web_archives/data")
require(XML)
require(RCurl)
### Creates the sequence of numbers to paginate with
pages<-seq(0, as.numeric(totalpages), 1)
### Make a character vector of URLs of all the search results
urls<-sprintf("http://tnaftindex.internetmemory.org/nutch-1.0-tna-distrib-ssd/opensearch?query=%s?page=%s", searchterm, pages)
### Read the html of each results page into a list
for(i in 1:length(urls)){
DF<-lapply(urls, function(x) readLines(x))
}
### Call the full-text search API
#############################################################
#### Enter your search term and the total number of API pages
#### to paginate through
searchterm<-"inequality"
totalpages<-"50"
############################################################
setwd("~/Dropbox/Side Projects/uk_govt_web_archives/data")
require(XML)
require(RCurl)
### Creates the sequence of numbers to paginate with
pages<-seq(0, as.numeric(totalpages), 1)
### Make a character vector of URLs of all the search results
urls<-sprintf("http://tnaftindex.internetmemory.org/nutch-1.0-tna-distrib-ssd/opensearch?query=%s?page=%s", searchterm, pages)
### Read the html of each results page into a list
for(i in 1:length(urls)){
DF<-lapply(urls, function(x) readLines(x))
}
require(XML)
require(RCurl)
### Creates the sequence of numbers to paginate with
pages<-seq(0, as.numeric(totalpages), 1)
### Make a character vector of URLs of all the search results
urls<-sprintf("http://tnaftindex.internetmemory.org/nutch-1.0-tna-distrib-ssd/opensearch?query=%s?page=%s", searchterm, pages)
### Read the html of each results page into a list
for(i in 1:length(urls)){
DF<-lapply(urls, function(x) readLines(x))
}
?tryCatch
qplot(Year, Freq, data=timeseries, geom="line", main="Frequency of \"inequality\" in Across All UK Govt Websites") + theme_bw()
save(DF, file="/Users/justin/Dropbox/Side Projects/uk_govt_web_archives/data/web_search_scrapes/api_inequality_50_pages.Rdata")
