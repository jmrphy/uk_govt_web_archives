DF<-lapply(urls, function(x) readLines(x))
}
DF[9]
searchterm<-"wage"
totalresults<-"200"
pages<-seq(0, as.numeric(totalresults), 10)
urls<-sprintf("http://webarchive.nationalarchives.gov.uk/search/?lang=en&noneW=&format=all&department_id_51=on&department_id_56=on&site=number10.gov.uk&department_id_54=on&search_type=website&start=%s&x=17&y=13&query=%s&exactW=&where=text", pages, searchterm)
for(i in 1:length(urls)){
DF<-lapply(urls, function(x) readLines(x))
}
grep('Archived at',DF)
?lapply
lapply(DF, function(x) grep('Archived at',x))
lapply(DF, function(x) grep('Archived at',x), simplify=TRUE)
lapply(DF, function(x) grep('Archived at',x))
items<-lapply(DF, function(x) grep('Archived at',x))
datelines<-lapply(DF, function(x) grep('Archived at',x))
items<-DF[grep('Archived at',DF[items])]
DF[datelines]
DF[,datelines]
DF[[datelines]]
DF[[,datelines]]
DF[datelines,]
df<-unlist(DF)
grep('Archived at',df)
datelines<-df[grep('Archived at',df)]
datelines<-df[grep('Archived at',df)] ### Select only lines in html containing "Archived at"
findlines<-df[grep('Archived at',df)] ### Select only lines in html containing "Archived at"
foundlines<-df[grep('Archived at',df)] ### Select only lines in html containing "Archived at"
mypattern = 'Archived at: ([^<]*)</span>' # Define a pattern to identify dates
datelines = grep(mypattern,foundlines,value=TRUE)
datelines
getexpr = function(s,g)substring(s,g,g+attr(g,'match.length')-1)
gg = gregexpr(mypattern,datelines)
matches = mapply(getexpr,datelines,gg)
result = gsub(mypattern,'\\1',matches)
names(result) = NULL
result
data <- as.data.frame(matrix(result,ncol=1,byrow=TRUE))
names(data) = c('date')
head(data)
require(lubridate)
?guess_formats
guess_formats(data$date, print_matches = TRUE)
guess_formats(data$date, order="1979-05-27 05:00:59" print_matches = TRUE)
data$year<-year(data$date)
date$year
data$year
summary(data$year)
summary(as.factor(data$year))
counts(as.factor(data$year))
count(as.factor(data$year))
table(as.factor(data$year))
timeseries<-table(as.factor(data$year))
timeseries<-as.data.frame(as.factor(data$year))
timeseries
timeseries<-as.data.frame(table(as.factor(data$year)))
View(timeseries)
View(timeseries)
View(timeseries)
require(ggplot2)
View(timeseries)
summary(timeseries$Freq)
summary(timeseries$Var1)
timeseries<-as.data.frame(table(data$year))
View(timeseries)
summary(timeseries$Var1)
data$year<-year(data$date)
timeseries<-as.data.frame(table(data$year))
View(timeseries)
summary(timeseries$Var1)
timeseries<-as.data.frame(table(as.numeric(data$year)))
summary(timeseries$Var1)
data$year<-year(data$date)
timeseries<-as.data.frame(table(as.numeric(data$year)))
summary(timeseries$Var1)
qplot(as.numeric(timeseries$Var1), timeseries$Freq)
qplot(timeseries$Var1, timeseries$Freq)
?qplot
qplot(timeseries$Var1, timeseries$Freq, geom="line") + theme_bw()
qplot(timeseries$Var1, timeseries$Freq, geom="line")
?qplot
qplot(timeseries$Var1, timeseries$Freq) + geom(line)
qplot(timeseries$Var1, timeseries$Freq) + geom_line() + theme_bw()
View(timeseries)
qplot(as.numeric(timeseries$Var1), timeseries$Freq) + geom_line() + theme_bw()
qplot(as.integer(timeseries$Var1), timeseries$Freq) + geom_line() + theme_bw()
?qplot
?geom_line
?qplot
qplot(Var1, Freq, data=timeseries) + geom_line() + theme_bw()
qplot(Var1, Freq, data=timeseries) + geom_line() + theme_bw()
?geom_line
qplot(Var1, Freq, data=timeseries) + geom_line(aes(Var1, Freq, data=timeseries)) + theme_bw()
?geom_line
data$year<-as.Date(data$year)
qplot(Var1, Freq, data=timeseries, geom="line") + theme_bw()
?lubridate
data$year<-year(data$date)
timeseries<-as.data.frame(table(data$year))
timeseries$year<-year(timeseries$year)
View(timeseries)
timeseries$year<-year(as.numeric(timeseries$year))
timeseries<-as.data.frame(table(data$date))
View(timeseries)
?as.Date
data$year<-year(data$date)
data$year<-as.Date(data$year)
timeseries<-as.data.frame(table(data$year))
data$year<-year(data$date)
timeseries<-as.data.frame(table(data$year))
View(timeseries)
timeseries$Year<-as.Date(timeseries$Var1, "%Y")
qplot(Year, Freq, data=timeseries, geom="line") + theme_bw()
?qplot
qplot(Year, Freq, data=timeseries, geom="line", main="Frequency of \"wage\" in Archive of Prime Minister's Website) + theme_bw()
qplot(Year, Freq, data=timeseries, geom="line", main="Frequency of /"wage/" in Archive of Prime Minister's Website) + theme_bw()
qplot(Year, Freq, data=timeseries, geom="line", main="Frequency of "wage" in Archive of Prime Minister's Website) + theme_bw()
qplot(Year, Freq, data=timeseries, geom="line", main="Frequency of "wage" in Archive of Prime Minister's Website") + theme_bw()
qplot(Year, Freq, data=timeseries, geom="line", main="Frequency of "\wage\" in Archive of Prime Minister's Website") + theme_bw()
qplot(Year, Freq, data=timeseries, geom="line", main="Frequency of \"wage\" in Archive of Prime Minister's Website") + theme_bw()
qplot(Year, Freq, data=timeseries, geom="line", main="Frequency of \"wage\" in National Archive of Prime Minister's Website") + theme_bw()
searchterm<-"inequality"
totalpages<-"300" # 3,355,211 total results
############################################################
require(XML)
require(RCurl)
### Creates the sequence of numbers to paginate with
pages<-seq(0, as.numeric(totalpages), 1)
### Make a character vector of URLs of all the search results
urls<-sprintf("http://tnaftindex.internetmemory.org/nutch-1.0-tna-distrib-ssd/opensearch?query=%s?page=%s", searchterm, pages)
for(i in 1:length(urls)){
DF<-lapply(urls, function(x) suppressWarnings(try(readLines(x), TRUE)))
}
totalpages<-"100" # 3,355,211 total results
pages<-seq(0, as.numeric(totalpages), 1)
### Make a character vector of URLs of all the search results
urls<-sprintf("http://tnaftindex.internetmemory.org/nutch-1.0-tna-distrib-ssd/opensearch?query=%s?page=%s", searchterm, pages)
for(i in 1:length(urls)){
DF<-lapply(urls, function(x) suppressWarnings(try(readLines(x), TRUE)))
if(i==length(urls)) break
}
for(i in 1:length(urls)){
DF<-lapply(urls, function(x) try(readLines(x), TRUE))
}
totalpages<-"5" # 3,355,211 total results
pages<-seq(0, as.numeric(totalpages), 1)
urls<-sprintf("http://tnaftindex.internetmemory.org/nutch-1.0-tna-distrib-ssd/opensearch?query=%s?page=%s", searchterm, pages)
totalpages<-"1" # 3,355,211 total results
pages<-seq(0, as.numeric(totalpages), 1)
pages<-seq(0, as.numeric(totalpages), 1)
urls<-sprintf("http://tnaftindex.internetmemory.org/nutch-1.0-tna-distrib-ssd/opensearch?query=%s?page=%s", searchterm, pages)
system.time(
for(i in 1:length(urls)){
DF<-lapply(urls, function(x) try(readLines(x), TRUE))
if(i==length(urls)) break
})
for(i in 1:length(urls)){
DF<-lapply(urls, function(x) try(readLines(x), TRUE))
if(i==totalpages) break
}
system.time(
for(i in 1:length(urls)){
DF<-lapply(urls, function(x) try(readLines(x), TRUE))
if(i==totalpages) break
})
system.time()
for(i in 1:length(urls)){
DF<-lapply(urls, function(x) suppressWarnings(try(readLines(x), TRUE)))
if(i==totalpages) break
})
system.time(
for(i in 1:length(urls)){
DF<-lapply(urls, function(x) suppressWarnings(try(readLines(x), TRUE)))
if(i==totalpages) break
})
rm(DF)
totalpages<-"4" # 3,355,211 total results
system.time(
for(i in 1:length(urls)){
DF<-lapply(urls, function(x) suppressWarnings(try(readLines(x), TRUE)))
if(i==totalpages) break
})
urls<-sprintf("http://tnaftindex.internetmemory.org/nutch-1.0-tna-distrib-ssd/opensearch?query=%s?page=%s", searchterm, pages)
pages<-seq(0, as.numeric(totalpages), 1)
totalpages<-"4" # 3,355,211 total results
searchterm<-"inequality"
totalpages<-"4" # 3,355,211 total results
############################################################
require(XML)
require(RCurl)
### Creates the sequence of numbers to paginate with
pages<-seq(0, as.numeric(totalpages), 1)
### Make a character vector of URLs of all the search results
urls<-sprintf("http://tnaftindex.internetmemory.org/nutch-1.0-tna-distrib-ssd/opensearch?query=%s?page=%s", searchterm, pages)
searchterm<-"inequality"
totalpages<-"3" # 3,355,211 total results
############################################################
require(XML)
require(RCurl)
### Creates the sequence of numbers to paginate with
pages<-seq(0, as.numeric(totalpages), 1)
### Make a character vector of URLs of all the search results
urls<-sprintf("http://tnaftindex.internetmemory.org/nutch-1.0-tna-distrib-ssd/opensearch?query=%s?page=%s", searchterm, pages)
### Read the html of each results page into a list
system.time(
for(i in 1:length(urls)){
DF<-lapply(urls, function(x) suppressWarnings(try(readLines(x), TRUE)))
if(i==totalpages) break
})
rm(DF)
DF<-lapply(urls, function(x) suppressWarnings(try(readLines(x), TRUE)))
rm(DF)
system.time(DF<-lapply(urls, function(x) suppressWarnings(try(readLines(x), TRUE))))
searchterm<-"inequality"
totalpages<-"1000" # 3,355,211 total results
############################################################
require(XML)
require(RCurl)
### Creates the sequence of numbers to paginate with
pages<-seq(0, as.numeric(totalpages), 1)
### Make a character vector of URLs of all the search results
urls<-sprintf("http://tnaftindex.internetmemory.org/nutch-1.0-tna-distrib-ssd/opensearch?query=%s?page=%s", searchterm, pages)
### Read the html of each results page into a list
DF<-lapply(urls, function(x) suppressWarnings(try(readLines(x), TRUE))))
searchterm<-"inequality"
totalpages<-"1000" # 3,355,211 total results
############################################################
require(XML)
require(RCurl)
### Creates the sequence of numbers to paginate with
pages<-seq(0, as.numeric(totalpages), 1)
### Make a character vector of URLs of all the search results
urls<-sprintf("http://tnaftindex.internetmemory.org/nutch-1.0-tna-distrib-ssd/opensearch?query=%s?page=%s", searchterm, pages)
### Read the html of each results page into a list
DF<-lapply(urls, function(x) suppressWarnings(try(readLines(x), TRUE)))
searchterm<-"inequality"
totalpages<-"100" # 3,355,211 total results
############################################################
require(XML)
require(RCurl)
### Creates the sequence of numbers to paginate with
pages<-seq(0, as.numeric(totalpages), 1)
### Make a character vector of URLs of all the search results
urls<-sprintf("http://tnaftindex.internetmemory.org/nutch-1.0-tna-distrib-ssd/opensearch?query=%s?page=%s", searchterm, pages)
### Read the html of each results page into a list
DF<-lapply(urls, function(x) suppressWarnings(try(readLines(x), TRUE)))
save(DF, file="~/data/api/api_inequality.Rdata")
setwd("~/Dropbox/Side Projects/uk_govt_web_archives")
save(DF, file="~/data/api/api_inequality.Rdata")
save(DF, file="/data/api/api_inequality.Rdata")
?save
save(DF, file="data/api/api_inequality.Rdata")
DF.inequality<-DF
##############################################################################
### Scrape full-text search results from the UK Government Website Archive API
##############################################################################
#############################################################
#### Enter your search term and the total number of API pages
#### to paginate through
searchterm<-"unemployment"
totalpages<-"100"
############################################################
require(XML)
require(RCurl)
### Creates the sequence of numbers to paginate with
pages<-seq(0, as.numeric(totalpages), 1)
### Make a character vector of URLs of all the search results
urls<-sprintf("http://tnaftindex.internetmemory.org/nutch-1.0-tna-distrib-ssd/opensearch?query=%s?page=%s", searchterm, pages)
### Read the html of each results page into a list
DF.unemployment<-lapply(urls, function(x) suppressWarnings(try(readLines(x), TRUE)))
save(DF.unemployment, file="data/api/api_unemployment.Rdata")
DF.unemployment[1]
##############################################################################
### Scrape full-text search results from the UK Government Website Archive API
##############################################################################
#############################################################
#### Enter your search term and the total number of API pages
#### to paginate through
searchterm<-"wage"
totalpages<-"100"
############################################################
require(XML)
require(RCurl)
### Creates the sequence of numbers to paginate with
pages<-seq(0, as.numeric(totalpages), 1)
### Make a character vector of URLs of all the search results
urls<-sprintf("http://tnaftindex.internetmemory.org/nutch-1.0-tna-distrib-ssd/opensearch?query=%s?page=%s", searchterm, pages)
### Read the html of each results page into a list
DF.wage<-lapply(urls, function(x) suppressWarnings(try(readLines(x), TRUE)))
##############################################################################
### Scrape full-text search results from the UK Government Website Archive API
##############################################################################
#############################################################
#### Enter your search term and the total number of API pages
#### to paginate through
searchterm<-"inflation"
totalpages<-"100"
############################################################
require(XML)
require(RCurl)
### Creates the sequence of numbers to paginate with
pages<-seq(0, as.numeric(totalpages), 1)
### Make a character vector of URLs of all the search results
urls<-sprintf("http://tnaftindex.internetmemory.org/nutch-1.0-tna-distrib-ssd/opensearch?query=%s?page=%s", searchterm, pages)
### Read the html of each results page into a list
DF.inflation<-lapply(urls, function(x) suppressWarnings(try(readLines(x), TRUE)))
save(DF.inflation, file="data/api/api_inflation.Rdata")
searchterm<-"profit"
totalpages<-"100"
############################################################
require(XML)
require(RCurl)
### Creates the sequence of numbers to paginate with
pages<-seq(0, as.numeric(totalpages), 1)
### Make a character vector of URLs of all the search results
urls<-sprintf("http://tnaftindex.internetmemory.org/nutch-1.0-tna-distrib-ssd/opensearch?query=%s?page=%s", searchterm, pages)
### Read the html of each results page into a list
DF.profit<-lapply(urls, function(x) suppressWarnings(try(readLines(x), TRUE)))
### Save
save(DF.profit, file="data/api/api_profit.Rdata")
searchterm<-"wage"
totalpages<-"100"
############################################################
require(XML)
require(RCurl)
### Creates the sequence of numbers to paginate with
pages<-seq(0, as.numeric(totalpages), 1)
### Make a character vector of URLs of all the search results
urls<-sprintf("http://tnaftindex.internetmemory.org/nutch-1.0-tna-distrib-ssd/opensearch?query=%s?page=%s", searchterm, pages)
### Read the html of each results page into a list
DF.wage<-lapply(urls, function(x) suppressWarnings(try(readLines(x), TRUE)))
### Save
save(DF.wage, file="data/api/api_wage.Rdata")
load(data/api/api_wage.Rdata)
load("data/api/api_wage.Rdata")
load("data/api/api_profit.Rdata")
load("data/api/api_unemployment.Rdata")
load("data/api/api_inequality.Rdata")
DF.inequality<-DF
save(DF.inequality, file="data/api/api_inequality.Rdata")
rn(DF)
rm(DF)
load("data/api/api_inflation.Rdata")
wagedata<-lapply(DF.wage, function(x) xmlParse(x))
profitdata<-lapply(DF.profit, function(x) xmlParse(x))
uenmploymentdata<-lapply(DF.unemployment, function(x) xmlParse(x))
require(XML)
require(RCurl)
profitdata<-lapply(DF.profit, function(x) xmlParse(x))
DF.profit[1]
dates <- lapply(DF.profit, function(x) xpathSApply(x,'//item/nutch:date',xmlValue))
DF.profit[5]
inequalitydata<-lapply(DF.unemployment, function(x) xmlParse(x))
wagedata<-lapply(DF.wage, function(x) xmlParse(x))
inflationdata<-lapply(DF.inflation, function(x) xmlParse(x))
uenmploymentdata<-lapply(DF.unemployment, function(x) xmlParse(x))
inequalitydata<-lxmlParse(DF.unemployment)
inequalitydata<-xmlParse(DF.unemployment)
profitdata<-lapply(DF.profit, function(x) try(xmlParse(x)))
wagedata<-lapply(DF.wage, function(x) try(xmlParse(x)))
profitdata<-lapply(DF.profit, function(x) try(xmlParse(x)))
uenmploymentdata<-lapply(DF.unemployment, function(x) try(xmlParse(x)))
inflationdata<-lapply(DF.inflation, function(x) try(xmlParse(x)))
inequalitydata<-lapply(DF.unemployment, function(x) try(xmlParse(x)))
wagedates <- lapply(DF.wage, function(x) xpathSApply(x,'//item/nutch:date',xmlValue))
wagedates <- lapply(wagedata, function(x) xpathSApply(x,'//item/nutch:date',xmlValue))
profitdates <- lapply(profitdata, function(x) xpathSApply(x,'//item/nutch:date',xmlValue))
profitdates <- lapply(profitdata, function(x) try(xpathSApply(x,'//item/nutch:date',xmlValue)))
unemploymentdates <- lapply(unemploymentdata, function(x) try(xpathSApply(x,'//item/nutch:date',xmlValue)))
unemploymentdata<-lapply(DF.unemployment, function(x) try(xmlParse(x)))
unemploymentdates <- lapply(unemploymentdata, function(x) try(xpathSApply(x,'//item/nutch:date',xmlValue)))
rm(uenmploymentdata)
inequalitydates <- lapply(inequalitydata, function(x) try(xpathSApply(x,'//item/nutch:date',xmlValue)))
require(lubridate)
require(lubridate)
wagedf<-as.data.frame(unlist(wagedates))
View(wagedf)
names(wagedf)<-c("timestamp")
View(wagedf)
wagedf$year<-substr(wagedf$timestamp, start=1, stop=4)
View(wagedf)
timeseries<-as.data.frame(table(datesdf$year))
wagetimeseries<-as.data.frame(table(wagedf$year))
wagetimeseries$Year<-as.Date(as.character(wagetimeseries$Var1), "%Y")
wagetimeseries$Year<-year(wagetimeseries$Year)
require(ggplot2)
plot<-qplot(Year, Freq, data=wagetimeseries, geom="line", main="Frequency of \"inequality\" in Across All UK Govt Websites") + theme_bw()
plot
inequalitydf<-as.data.frame(unlist(inequalitydates))
names(inequalitydf)<-c("timestamp")
inequalitydf$year<-substr(inequalitydf$timestamp, start=1, stop=4)
inequalitytimeseries<-as.data.frame(table(inequalitydf$year))
inequalitytimeseries$Year<-as.Date(as.character(inequalitytimeseries$Var1), "%Y")
inequalitytimeseries$Year<-year(inequalitytimeseries$Year)
inflationdf<-as.data.frame(unlist(inflationdates))
names(inflationdf)<-c("timestamp")
inflationdf$year<-substr(inflationdf$timestamp, start=1, stop=4)
inflationtimeseries<-as.data.frame(table(inflationdf$year))
inflationtimeseries$Year<-as.Date(as.character(inflationtimeseries$Var1), "%Y")
inflationtimeseries$Year<-year(inflationtimeseries$Year)
inflationdates <- lapply(inflationdata, function(x) try(xpathSApply(x,'//item/nutch:date',xmlValue)))
inflationdata<-lapply(DF.inflation, function(x) try(xmlParse(x)))
inflationdates <- lapply(inflationdata, function(x) try(xpathSApply(x,'//item/nutch:date',xmlValue)))
inflationdf<-as.data.frame(unlist(inflationdates))
names(inflationdf)<-c("timestamp")
inflationdf$year<-substr(inflationdf$timestamp, start=1, stop=4)
inflationtimeseries<-as.data.frame(table(inflationdf$year))
inflationtimeseries$Year<-as.Date(as.character(inflationtimeseries$Var1), "%Y")
inflationtimeseries$Year<-year(inflationtimeseries$Year)
unemploymentdf<-as.data.frame(unlist(unemploymentdates))
names(unemploymentdf)<-c("timestamp")
unemploymentdf$year<-substr(unemploymentdf$timestamp, start=1, stop=4)
unemploymenttimeseries<-as.data.frame(table(unemploymentdf$year))
unemploymenttimeseries$Year<-as.Date(as.character(unemploymenttimeseries$Var1), "%Y")
unemploymenttimeseries$Year<-year(unemploymenttimeseries$Year)
profitdf<-as.data.frame(unlist(profitdates))
names(profitdf)<-c("timestamp")
profitdf$year<-substr(profitdf$timestamp, start=1, stop=4)
profittimeseries<-as.data.frame(table(profitdf$year))
profittimeseries$Year<-as.Date(as.character(profittimeseries$Var1), "%Y")
profittimeseries$Year<-year(profittimeseries$Year)
wagedf<-as.data.frame(unlist(wagedates))
names(wagedf)<-c("timestamp")
wagedf$year<-substr(wagedf$timestamp, start=1, stop=4)
wagetimeseries<-as.data.frame(table(wagedf$year))
wagetimeseries$Year<-as.Date(as.character(wagetimeseries$Var1), "%Y")
wagetimeseries$Year<-year(wagetimeseries$Year)
?qplot
df<-rbind(wagedf,profitdf,unemploymentdf,inflationdf,inequalitydf)
View(df)
df<-rbind(wagetimeseries,profittimeseries,unemploymenttimeseries, inflationtimeseries,inequalitytimeseries)
View(df)
wagetimeseries$Term<-"Wage"
View(wagetimeseries)
inequalitytimeseries$Term<-"Inequality"
wagedf<-as.data.frame(unlist(wagedates))
names(wagedf)<-c("timestamp")
wagedf$year<-substr(wagedf$timestamp, start=1, stop=4)
wagetimeseries<-as.data.frame(table(wagedf$year))
wagetimeseries$Year<-as.Date(as.character(wagetimeseries$Var1), "%Y")
wagetimeseries$Year<-year(wagetimeseries$Year)
wagetimeseries$Term<-"Wage"
profitdf<-as.data.frame(unlist(profitdates))
names(profitdf)<-c("timestamp")
profitdf$year<-substr(profitdf$timestamp, start=1, stop=4)
profittimeseries<-as.data.frame(table(profitdf$year))
profittimeseries$Year<-as.Date(as.character(profittimeseries$Var1), "%Y")
profittimeseries$Year<-year(profittimeseries$Year)
profittimeseries$Term<-"Profit"
unemploymentdf<-as.data.frame(unlist(unemploymentdates))
names(unemploymentdf)<-c("timestamp")
unemploymentdf$year<-substr(unemploymentdf$timestamp, start=1, stop=4)
unemploymenttimeseries<-as.data.frame(table(unemploymentdf$year))
unemploymenttimeseries$Year<-as.Date(as.character(unemploymenttimeseries$Var1), "%Y")
unemploymenttimeseries$Year<-year(unemploymenttimeseries$Year)
unemploymenttimeseries$Term<-"Unemployment"
inflationdf<-as.data.frame(unlist(inflationdates))
names(inflationdf)<-c("timestamp")
inflationdf$year<-substr(inflationdf$timestamp, start=1, stop=4)
inflationtimeseries<-as.data.frame(table(inflationdf$year))
inflationtimeseries$Year<-as.Date(as.character(inflationtimeseries$Var1), "%Y")
inflationtimeseries$Year<-year(inflationtimeseries$Year)
inflationtimeseries$Term<-"Inflation"
inequalitydf<-as.data.frame(unlist(inequalitydates))
names(inequalitydf)<-c("timestamp")
inequalitydf$year<-substr(inequalitydf$timestamp, start=1, stop=4)
inequalitytimeseries<-as.data.frame(table(inequalitydf$year))
inequalitytimeseries$Year<-as.Date(as.character(inequalitytimeseries$Var1), "%Y")
inequalitytimeseries$Year<-year(inequalitytimeseries$Year)
inequalitytimeseries$Term<-"Inequality"
df<-rbind(wagetimeseries,profittimeseries,unemploymenttimeseries, inflationtimeseries,inequalitytimeseries)
View(df)
View(df)
plot<-qplot(Year, Freq, data=df, geom="line", colour=Term, main="Frequency of \"inequality\" in Across All UK Govt Websites") + theme_bw()
plot
plot<-qplot(Year, Freq, data=df, geom="line", colour=Term, main="Frequency of economic terms across all UK Gov't Websites") + theme_bw()
plot
plot<-qplot(Year, Freq, data=df, geom="line", colour=Term, main="Frequency of Economic Terms Across All UK Gov't Websites") + theme_bw()
plot
?ggsave
ggsave(plot, "~/graphs/economic_terms.png")
qplot(Year, Freq, data=df, geom="line", colour=Term, main="Frequency of Economic Terms Across All UK Gov't Websites") + theme_bw()
ggsave("~/graphs/economic_terms.png")
ggsave("/graphs/economic_terms.png")
?ggsave
ggsave(filename="economic_terms.png", path="/graphs/")
ggsave(filename="economic_terms.png", path="/graphs")
setwd("~/Dropbox/Side Projects/uk_govt_web_archives/uk_govt_web_archives")
setwd("~/Dropbox/Side Projects/uk_govt_web_archives")
qplot(Year, Freq, data=df, geom="line", colour=Term, main="Frequency of Economic Terms Across All UK Gov't Websites") + theme_bw()
ggsave(filename="economic_terms.png", path="/graphs")
ggsave(file="/graphs/economic_terms.png")
ggsave(file="economic_terms.png")
ggsave(file="economic_terms.png", path="/graphs/")
ggsave(file="economic_terms.png", path="/graphs")
ggsave(file="economic_terms.pdf", path="/graphs")
qplot(Year, Freq, data=df, geom="line", colour=Term, main="Frequency of Economic Terms Across All UK Gov't Websites") + theme_bw()
ggsave(file="economic_terms.pdf", path="/graphs")
ggsave(file="economic_terms.pdf", path="~/graphs")
setwd("~/Dropbox/Side Projects/uk_govt_web_archives/graphs")
setwd("/graphs")
setwd("graphs")
setwd("~/Dropbox/Side Projects/uk_govt_web_archives")
setwd("/graphs")
setwd("uk_govt_web_archives/graphs")
png("mygraph.png")
?png
dev.off()
png("graphs/term_comparison_graph.png")
qplot(Year, Freq, data=df, geom="line", colour=Term, main="Frequency of Economic Terms Across All UK Gov't Websites") + theme_bw()
dev.off()
